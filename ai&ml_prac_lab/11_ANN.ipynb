{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Collecting tensorflow-intel==2.15.0\n",
      "  Downloading tensorflow_intel-2.15.0-cp310-cp310-win_amd64.whl (300.9 MB)\n",
      "     -------------------------------------- 300.9/300.9 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (22.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.25.1-cp310-abi3-win_amd64.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Collecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
      "     -------------------------------------- 938.6/938.6 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 4.9 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.60.0-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 4.6 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "     -------------------------------------- 130.2/130.2 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "     -------------------------------------- 442.0/442.0 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.23.5)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.26.1-py2.py3-none-any.whl (186 kB)\n",
      "     -------------------------------------- 186.4/186.4 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.2)\n",
      "Collecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "     -------------------------------------- 422.5/422.5 kB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, oauthlib, ml-dtypes, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.26.1 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.0 keras-2.15.0 libclang-16.0.6 ml-dtypes-0.2.0 oauthlib-3.2.2 protobuf-4.23.4 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-intel-2.15.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Isnbo0jzRHu4",
    "outputId": "872e1544-5a94-4478-f58a-1cb472cd9129"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess your data (replace with your data loading code)\n",
    "data = pd.read_csv('transfusion.data')\n",
    "data = data.sample(frac=1,random_state=123).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adadelta',\n",
       " 'Adafactor',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'Ftrl',\n",
       " 'Lion',\n",
       " 'Nadam',\n",
       " 'Optimizer',\n",
       " 'RMSprop',\n",
       " 'SGD',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'deserialize',\n",
       " 'experimental',\n",
       " 'get',\n",
       " 'legacy',\n",
       " 'schedules',\n",
       " 'serialize']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying subroutines\n",
    "#dir(tf.keras.losses)\n",
    "dir(tf.keras.optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data)[:, 0:-1]\n",
    "Y = np.array(data)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(11, activation='relu'),\n",
    "    keras.layers.Dense(7, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='relu'),\n",
    "    keras.layers.Dense(Y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 9.0947 - accuracy: 0.7718 - val_loss: 6.2803 - val_accuracy: 0.7326\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.5005 - accuracy: 0.7718 - val_loss: 3.0746 - val_accuracy: 0.7326\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.1111 - accuracy: 0.7718 - val_loss: 1.4526 - val_accuracy: 0.7326\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9776 - accuracy: 0.7718 - val_loss: 0.8706 - val_accuracy: 0.7326\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.7718 - val_loss: 0.7309 - val_accuracy: 0.7326\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7718 - val_loss: 0.7176 - val_accuracy: 0.7326\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7718 - val_loss: 0.7160 - val_accuracy: 0.7326\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.7718 - val_loss: 0.7040 - val_accuracy: 0.7326\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.7718 - val_loss: 0.6923 - val_accuracy: 0.7326\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.7718 - val_loss: 0.6966 - val_accuracy: 0.7326\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.7718 - val_loss: 0.6925 - val_accuracy: 0.7326\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.7718 - val_loss: 0.6877 - val_accuracy: 0.7326\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.7718 - val_loss: 0.6788 - val_accuracy: 0.7326\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.7718 - val_loss: 0.6747 - val_accuracy: 0.7326\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.7718 - val_loss: 0.6812 - val_accuracy: 0.7326\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.7718 - val_loss: 0.6590 - val_accuracy: 0.7326\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7718 - val_loss: 0.6537 - val_accuracy: 0.7326\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7718 - val_loss: 0.6506 - val_accuracy: 0.7326\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.7718 - val_loss: 0.6470 - val_accuracy: 0.7326\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7718 - val_loss: 0.6516 - val_accuracy: 0.7326\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7718 - val_loss: 0.6392 - val_accuracy: 0.7326\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.7718 - val_loss: 0.6276 - val_accuracy: 0.7326\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.7718 - val_loss: 0.6721 - val_accuracy: 0.7326\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7718 - val_loss: 0.6621 - val_accuracy: 0.7326\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.7718 - val_loss: 0.6554 - val_accuracy: 0.7326\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.7718 - val_loss: 0.6448 - val_accuracy: 0.7326\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.7718 - val_loss: 0.6337 - val_accuracy: 0.7326\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7718 - val_loss: 0.6342 - val_accuracy: 0.7326\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.7718 - val_loss: 0.6273 - val_accuracy: 0.7326\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7718 - val_loss: 0.6280 - val_accuracy: 0.7326\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7718 - val_loss: 0.6251 - val_accuracy: 0.7326\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7718 - val_loss: 0.6128 - val_accuracy: 0.7326\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.7718 - val_loss: 0.6161 - val_accuracy: 0.7326\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7718 - val_loss: 0.6031 - val_accuracy: 0.7326\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.7718 - val_loss: 0.6126 - val_accuracy: 0.7326\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7718 - val_loss: 0.6299 - val_accuracy: 0.7326\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.7718 - val_loss: 0.6480 - val_accuracy: 0.7326\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7718 - val_loss: 0.6145 - val_accuracy: 0.7326\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7718 - val_loss: 0.6227 - val_accuracy: 0.7326\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5719 - accuracy: 0.7718 - val_loss: 0.6011 - val_accuracy: 0.7326\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7718 - val_loss: 0.6059 - val_accuracy: 0.7326\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.7718 - val_loss: 0.6152 - val_accuracy: 0.7326\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.7718 - val_loss: 0.6155 - val_accuracy: 0.7326\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7683 - val_loss: 0.6604 - val_accuracy: 0.7326\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7718 - val_loss: 0.6172 - val_accuracy: 0.7326\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.7718 - val_loss: 0.5941 - val_accuracy: 0.7326\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7718 - val_loss: 0.6019 - val_accuracy: 0.7326\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7718 - val_loss: 0.6021 - val_accuracy: 0.7326\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7718 - val_loss: 0.6052 - val_accuracy: 0.7326\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7718 - val_loss: 0.5856 - val_accuracy: 0.7326\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7718 - val_loss: 0.5951 - val_accuracy: 0.7326\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7718 - val_loss: 0.5881 - val_accuracy: 0.7326\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7718 - val_loss: 0.5968 - val_accuracy: 0.7326\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7718 - val_loss: 0.5880 - val_accuracy: 0.7326\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7718 - val_loss: 0.5901 - val_accuracy: 0.7326\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7718 - val_loss: 0.5865 - val_accuracy: 0.7326\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7718 - val_loss: 0.5934 - val_accuracy: 0.7326\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7718 - val_loss: 0.5940 - val_accuracy: 0.7326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7718 - val_loss: 0.6006 - val_accuracy: 0.7326\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7718 - val_loss: 0.5853 - val_accuracy: 0.7326\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7718 - val_loss: 0.5873 - val_accuracy: 0.7326\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7718 - val_loss: 0.5903 - val_accuracy: 0.7326\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7718 - val_loss: 0.5663 - val_accuracy: 0.7380\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7718 - val_loss: 0.5889 - val_accuracy: 0.7326\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7718 - val_loss: 0.5778 - val_accuracy: 0.7326\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7718 - val_loss: 0.5733 - val_accuracy: 0.7326\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7718 - val_loss: 0.6097 - val_accuracy: 0.7326\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7718 - val_loss: 0.5729 - val_accuracy: 0.7326\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7718 - val_loss: 0.5692 - val_accuracy: 0.7326\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7718 - val_loss: 0.5841 - val_accuracy: 0.7326\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7718 - val_loss: 0.5757 - val_accuracy: 0.7326\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7718 - val_loss: 0.5696 - val_accuracy: 0.7326\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7718 - val_loss: 0.5659 - val_accuracy: 0.7326\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7718 - val_loss: 0.5698 - val_accuracy: 0.7326\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7718 - val_loss: 0.5792 - val_accuracy: 0.7326\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7718 - val_loss: 0.5703 - val_accuracy: 0.7326\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7718 - val_loss: 0.5711 - val_accuracy: 0.7326\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7718 - val_loss: 0.5642 - val_accuracy: 0.7326\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7718 - val_loss: 0.5722 - val_accuracy: 0.7326\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7718 - val_loss: 0.5730 - val_accuracy: 0.7326\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7701 - val_loss: 0.5948 - val_accuracy: 0.7326\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7718 - val_loss: 0.5758 - val_accuracy: 0.7326\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7718 - val_loss: 0.5670 - val_accuracy: 0.7326\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7736 - val_loss: 0.5681 - val_accuracy: 0.7380\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7701 - val_loss: 0.5676 - val_accuracy: 0.7326\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7701 - val_loss: 0.5581 - val_accuracy: 0.7326\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7701 - val_loss: 0.5682 - val_accuracy: 0.7326\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7718 - val_loss: 0.5583 - val_accuracy: 0.7326\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7718 - val_loss: 0.5643 - val_accuracy: 0.7326\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7718 - val_loss: 0.5545 - val_accuracy: 0.7326\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7736 - val_loss: 0.5613 - val_accuracy: 0.7326\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7718 - val_loss: 0.5553 - val_accuracy: 0.7326\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7736 - val_loss: 0.5556 - val_accuracy: 0.7326\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7718 - val_loss: 0.5502 - val_accuracy: 0.7380\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7772 - val_loss: 0.5472 - val_accuracy: 0.7380\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7718 - val_loss: 0.5532 - val_accuracy: 0.7326\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7718 - val_loss: 0.5516 - val_accuracy: 0.7326\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7736 - val_loss: 0.5528 - val_accuracy: 0.7380\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7718 - val_loss: 0.5545 - val_accuracy: 0.7326\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7754 - val_loss: 0.5502 - val_accuracy: 0.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1485ce27a30>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='BinaryCrossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7380\n",
      "Testing Accuracy: 0.7379679083824158\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       137\n",
      "           1       1.00      0.02      0.04        50\n",
      "\n",
      "    accuracy                           0.74       187\n",
      "   macro avg       0.87      0.51      0.44       187\n",
      "weighted avg       0.81      0.74      0.63       187\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Testing Accuracy: {}\".format(accuracy[1]))\n",
    "\n",
    "# Predict and evaluate\n",
    "Y_result = model.predict(X_test)\n",
    "Y_result = np.argmax(Y_result, axis=1)\n",
    "Y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "classification_rep = classification_report(Y_test, Y_result)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# Calculate fpr and tpr\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_result)\n",
    "\n",
    "# Plot ROC curve\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.02, 1.  ])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHEAT-SEEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Isnbo0jzRHu4",
    "outputId": "872e1544-5a94-4478-f58a-1cb472cd9129"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess your data (replace with your data loading code)\n",
    "data = pd.read_csv('seeds_dataset.txt',names = [1,2,3,4,5,6,7,8],sep='\\s+')\n",
    "data = data.sample(frac=1,random_state=123).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BinaryCrossentropy',\n",
       " 'BinaryFocalCrossentropy',\n",
       " 'CategoricalCrossentropy',\n",
       " 'CategoricalFocalCrossentropy',\n",
       " 'CategoricalHinge',\n",
       " 'CosineSimilarity',\n",
       " 'Hinge',\n",
       " 'Huber',\n",
       " 'KLD',\n",
       " 'KLDivergence',\n",
       " 'LogCosh',\n",
       " 'Loss',\n",
       " 'MAE',\n",
       " 'MAPE',\n",
       " 'MSE',\n",
       " 'MSLE',\n",
       " 'MeanAbsoluteError',\n",
       " 'MeanAbsolutePercentageError',\n",
       " 'MeanSquaredError',\n",
       " 'MeanSquaredLogarithmicError',\n",
       " 'Poisson',\n",
       " 'Reduction',\n",
       " 'SparseCategoricalCrossentropy',\n",
       " 'SquaredHinge',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'binary_crossentropy',\n",
       " 'binary_focal_crossentropy',\n",
       " 'categorical_crossentropy',\n",
       " 'categorical_focal_crossentropy',\n",
       " 'categorical_hinge',\n",
       " 'cosine_similarity',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'hinge',\n",
       " 'huber',\n",
       " 'kl_divergence',\n",
       " 'kld',\n",
       " 'kullback_leibler_divergence',\n",
       " 'log_cosh',\n",
       " 'logcosh',\n",
       " 'mae',\n",
       " 'mape',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_logarithmic_error',\n",
       " 'mse',\n",
       " 'msle',\n",
       " 'poisson',\n",
       " 'serialize',\n",
       " 'sparse_categorical_crossentropy',\n",
       " 'squared_hinge']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying subroutines\n",
    "dir(tf.keras.losses)\n",
    "#dir(tf.keras.optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data)[:, 0:-1]\n",
    "Y = np.array(data)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(11, activation='relu'),\n",
    "    keras.layers.Dense(7, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='relu'),\n",
    "    keras.layers.Dense(Y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 73ms/step - loss: 1.1802 - accuracy: 0.3121 - val_loss: 1.0404 - val_accuracy: 0.3962\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0675 - accuracy: 0.3885 - val_loss: 1.0781 - val_accuracy: 0.5849\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0910 - accuracy: 0.4459 - val_loss: 1.0983 - val_accuracy: 0.3396\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0941 - accuracy: 0.4268 - val_loss: 1.0871 - val_accuracy: 0.5094\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0721 - accuracy: 0.5414 - val_loss: 1.0414 - val_accuracy: 0.4528\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0606 - accuracy: 0.3376 - val_loss: 1.0328 - val_accuracy: 0.3962\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0661 - accuracy: 0.3248 - val_loss: 1.0316 - val_accuracy: 0.3962\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0599 - accuracy: 0.3376 - val_loss: 1.0329 - val_accuracy: 0.4528\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0576 - accuracy: 0.4522 - val_loss: 1.0463 - val_accuracy: 0.6604\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0556 - accuracy: 0.5541 - val_loss: 1.0341 - val_accuracy: 0.5660\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0517 - accuracy: 0.4140 - val_loss: 1.0256 - val_accuracy: 0.4717\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0493 - accuracy: 0.3694 - val_loss: 1.0238 - val_accuracy: 0.5094\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0476 - accuracy: 0.4650 - val_loss: 1.0279 - val_accuracy: 0.6226\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0445 - accuracy: 0.4904 - val_loss: 1.0217 - val_accuracy: 0.5849\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0407 - accuracy: 0.5032 - val_loss: 1.0192 - val_accuracy: 0.5849\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0380 - accuracy: 0.4841 - val_loss: 1.0136 - val_accuracy: 0.5660\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0357 - accuracy: 0.4968 - val_loss: 1.0115 - val_accuracy: 0.5849\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0331 - accuracy: 0.4777 - val_loss: 1.0066 - val_accuracy: 0.5660\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0295 - accuracy: 0.5032 - val_loss: 1.0069 - val_accuracy: 0.6792\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0299 - accuracy: 0.6242 - val_loss: 1.0058 - val_accuracy: 0.6792\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0232 - accuracy: 0.5860 - val_loss: 0.9956 - val_accuracy: 0.5660\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0228 - accuracy: 0.4204 - val_loss: 0.9884 - val_accuracy: 0.5283\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0226 - accuracy: 0.5096 - val_loss: 0.9971 - val_accuracy: 0.6792\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0153 - accuracy: 0.6051 - val_loss: 0.9855 - val_accuracy: 0.6226\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0147 - accuracy: 0.4713 - val_loss: 0.9804 - val_accuracy: 0.5849\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0092 - accuracy: 0.5860 - val_loss: 0.9874 - val_accuracy: 0.6981\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0075 - accuracy: 0.5860 - val_loss: 0.9760 - val_accuracy: 0.6981\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0023 - accuracy: 0.5860 - val_loss: 0.9764 - val_accuracy: 0.6792\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0002 - accuracy: 0.5860 - val_loss: 0.9669 - val_accuracy: 0.6981\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9994 - accuracy: 0.6242 - val_loss: 0.9714 - val_accuracy: 0.6981\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.9954 - accuracy: 0.5350 - val_loss: 0.9544 - val_accuracy: 0.5660\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9948 - accuracy: 0.4268 - val_loss: 0.9547 - val_accuracy: 0.6792\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9883 - accuracy: 0.6178 - val_loss: 0.9711 - val_accuracy: 0.6981\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9852 - accuracy: 0.6497 - val_loss: 0.9463 - val_accuracy: 0.6604\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9843 - accuracy: 0.4650 - val_loss: 0.9401 - val_accuracy: 0.6038\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9794 - accuracy: 0.6178 - val_loss: 0.9527 - val_accuracy: 0.6981\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9743 - accuracy: 0.6561 - val_loss: 0.9408 - val_accuracy: 0.6792\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9685 - accuracy: 0.6051 - val_loss: 0.9299 - val_accuracy: 0.6604\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9689 - accuracy: 0.5223 - val_loss: 0.9255 - val_accuracy: 0.6604\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9640 - accuracy: 0.6051 - val_loss: 0.9382 - val_accuracy: 0.6981\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9634 - accuracy: 0.6943 - val_loss: 0.9281 - val_accuracy: 0.6981\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9562 - accuracy: 0.5605 - val_loss: 0.9116 - val_accuracy: 0.5849\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9580 - accuracy: 0.4713 - val_loss: 0.9122 - val_accuracy: 0.6981\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9501 - accuracy: 0.6561 - val_loss: 0.9241 - val_accuracy: 0.6981\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9472 - accuracy: 0.6688 - val_loss: 0.9067 - val_accuracy: 0.6792\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9432 - accuracy: 0.6115 - val_loss: 0.8998 - val_accuracy: 0.6981\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9419 - accuracy: 0.6688 - val_loss: 0.9077 - val_accuracy: 0.7170\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9370 - accuracy: 0.6561 - val_loss: 0.8922 - val_accuracy: 0.6792\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9338 - accuracy: 0.6306 - val_loss: 0.8941 - val_accuracy: 0.7170\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9291 - accuracy: 0.6752 - val_loss: 0.8877 - val_accuracy: 0.6981\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9260 - accuracy: 0.6369 - val_loss: 0.8810 - val_accuracy: 0.6792\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9222 - accuracy: 0.6497 - val_loss: 0.8827 - val_accuracy: 0.7170\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9185 - accuracy: 0.6624 - val_loss: 0.8774 - val_accuracy: 0.7170\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9152 - accuracy: 0.6306 - val_loss: 0.8717 - val_accuracy: 0.6981\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9113 - accuracy: 0.6688 - val_loss: 0.8700 - val_accuracy: 0.7170\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.9083 - accuracy: 0.6943 - val_loss: 0.8679 - val_accuracy: 0.7170\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9051 - accuracy: 0.6561 - val_loss: 0.8576 - val_accuracy: 0.6981\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9026 - accuracy: 0.6752 - val_loss: 0.8612 - val_accuracy: 0.7170\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8990 - accuracy: 0.6624 - val_loss: 0.8507 - val_accuracy: 0.6981\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8948 - accuracy: 0.6433 - val_loss: 0.8497 - val_accuracy: 0.7170\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8908 - accuracy: 0.6943 - val_loss: 0.8508 - val_accuracy: 0.6981\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.8883 - accuracy: 0.7070 - val_loss: 0.8403 - val_accuracy: 0.7170\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8927 - accuracy: 0.5796 - val_loss: 0.8314 - val_accuracy: 0.6981\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8798 - accuracy: 0.6943 - val_loss: 0.8512 - val_accuracy: 0.7547\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8836 - accuracy: 0.7707 - val_loss: 0.8345 - val_accuracy: 0.6981\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8737 - accuracy: 0.6369 - val_loss: 0.8206 - val_accuracy: 0.7170\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8741 - accuracy: 0.6624 - val_loss: 0.8280 - val_accuracy: 0.7170\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8689 - accuracy: 0.7197 - val_loss: 0.8238 - val_accuracy: 0.7170\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8652 - accuracy: 0.6752 - val_loss: 0.8141 - val_accuracy: 0.7170\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8633 - accuracy: 0.7006 - val_loss: 0.8208 - val_accuracy: 0.7170\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8577 - accuracy: 0.7134 - val_loss: 0.8065 - val_accuracy: 0.7170\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8606 - accuracy: 0.6178 - val_loss: 0.8039 - val_accuracy: 0.7170\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8552 - accuracy: 0.7261 - val_loss: 0.8240 - val_accuracy: 0.7736\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8528 - accuracy: 0.7389 - val_loss: 0.7957 - val_accuracy: 0.6981\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8492 - accuracy: 0.6497 - val_loss: 0.7926 - val_accuracy: 0.7170\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8486 - accuracy: 0.7452 - val_loss: 0.8110 - val_accuracy: 0.7736\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8415 - accuracy: 0.7452 - val_loss: 0.7856 - val_accuracy: 0.6981\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8402 - accuracy: 0.6433 - val_loss: 0.7825 - val_accuracy: 0.7170\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8331 - accuracy: 0.7452 - val_loss: 0.7923 - val_accuracy: 0.7547\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8340 - accuracy: 0.7707 - val_loss: 0.7849 - val_accuracy: 0.7170\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8281 - accuracy: 0.6815 - val_loss: 0.7723 - val_accuracy: 0.6981\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8267 - accuracy: 0.6815 - val_loss: 0.7762 - val_accuracy: 0.7170\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8266 - accuracy: 0.7516 - val_loss: 0.7843 - val_accuracy: 0.7736\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8198 - accuracy: 0.7261 - val_loss: 0.7635 - val_accuracy: 0.6981\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8240 - accuracy: 0.6561 - val_loss: 0.7649 - val_accuracy: 0.7170\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8156 - accuracy: 0.7643 - val_loss: 0.7711 - val_accuracy: 0.7736\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8113 - accuracy: 0.7516 - val_loss: 0.7567 - val_accuracy: 0.7170\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8087 - accuracy: 0.7261 - val_loss: 0.7548 - val_accuracy: 0.7170\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8061 - accuracy: 0.7325 - val_loss: 0.7572 - val_accuracy: 0.7547\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8041 - accuracy: 0.7580 - val_loss: 0.7553 - val_accuracy: 0.7547\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8006 - accuracy: 0.7261 - val_loss: 0.7436 - val_accuracy: 0.7358\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7983 - accuracy: 0.7197 - val_loss: 0.7499 - val_accuracy: 0.7736\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7975 - accuracy: 0.7771 - val_loss: 0.7467 - val_accuracy: 0.7736\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7955 - accuracy: 0.7006 - val_loss: 0.7361 - val_accuracy: 0.7170\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7898 - accuracy: 0.7452 - val_loss: 0.7427 - val_accuracy: 0.7736\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7888 - accuracy: 0.7580 - val_loss: 0.7351 - val_accuracy: 0.7547\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7846 - accuracy: 0.7707 - val_loss: 0.7330 - val_accuracy: 0.7547\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7835 - accuracy: 0.7516 - val_loss: 0.7264 - val_accuracy: 0.7170\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7805 - accuracy: 0.7452 - val_loss: 0.7322 - val_accuracy: 0.7736\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7780 - accuracy: 0.7580 - val_loss: 0.7241 - val_accuracy: 0.7547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14867be38b0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='CategoricalCrossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.36216223, 0.30298802, 0.33484977],\n",
       "       [0.17809585, 0.7549672 , 0.06693693],\n",
       "       [0.21934807, 0.682807  , 0.09784494],\n",
       "       [0.17050247, 0.7675142 , 0.06198334],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.33786148, 0.4069279 , 0.2552106 ],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.2758166 , 0.5697172 , 0.15446614],\n",
       "       [0.34684607, 0.3749794 , 0.27817452],\n",
       "       [0.3538539 , 0.3461763 , 0.2999698 ],\n",
       "       [0.25836107, 0.6069122 , 0.13472675],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.29135108, 0.53436244, 0.1742865 ],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.14191115, 0.81295675, 0.04513205],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.36872607, 0.21891755, 0.41235638],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.36125192, 0.30856147, 0.3301866 ],\n",
       "       [0.15217197, 0.7969644 , 0.05086364],\n",
       "       [0.22426812, 0.67369616, 0.10203572],\n",
       "       [0.34227064, 0.3917865 , 0.2659428 ],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.35062444, 0.36000946, 0.28936613],\n",
       "       [0.17917816, 0.75316155, 0.06766025],\n",
       "       [0.31533954, 0.47401267, 0.21064773],\n",
       "       [0.23205405, 0.6590282 , 0.10891778],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.1992308 , 0.7188885 , 0.08188066],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.16380702, 0.77840585, 0.05778714],\n",
       "       [0.2801325 , 0.5601307 , 0.15973684],\n",
       "       [0.11357213, 0.85539544, 0.03103244],\n",
       "       [0.29276386, 0.53102213, 0.17621404],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.1464967 , 0.8058523 , 0.04765103],\n",
       "       [0.11872241, 0.8478665 , 0.03341112],\n",
       "       [0.18465032, 0.74396485, 0.07138481],\n",
       "       [0.36836302, 0.20754   , 0.424097  ],\n",
       "       [0.23897415, 0.6457192 , 0.11530669],\n",
       "       [0.28042343, 0.5594783 , 0.1600983 ],\n",
       "       [0.36828843, 0.24524046, 0.38647112],\n",
       "       [0.34057128, 0.39773116, 0.26169756],\n",
       "       [0.31549492, 0.4735922 , 0.21091293],\n",
       "       [0.33144262, 0.42754382, 0.24101357],\n",
       "       [0.35349858, 0.3477546 , 0.29874682],\n",
       "       [0.16133499, 0.7823875 , 0.05627751],\n",
       "       [0.09585599, 0.88068616, 0.02345784],\n",
       "       [0.16362798, 0.7786949 , 0.0576771 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7241 - accuracy: 0.7547\n",
      "Testing Accuracy: 0.7547169923782349\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.38        17\n",
      "           1       0.66      1.00      0.79        21\n",
      "           2       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.75        53\n",
      "   macro avg       0.85      0.75      0.70        53\n",
      "weighted avg       0.83      0.75      0.70        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, Y_test)\n",
    "print(\"Testing Accuracy: {}\".format(accuracy[1]))\n",
    "\n",
    "# Predict and evaluate\n",
    "Y_result = model.predict(X_test)\n",
    "Y_result = np.argmax(Y_result, axis=1)\n",
    "Y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "classification_rep = classification_report(Y_test, Y_result)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
